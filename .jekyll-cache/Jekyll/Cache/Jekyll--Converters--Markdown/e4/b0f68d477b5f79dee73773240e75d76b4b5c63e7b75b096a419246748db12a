I"E<p>by Tim Christy<br />
<br /></p>
<h3 id="introduction">Introduction</h3>
<p>What is web-scraping? It’s taking data from web pages and storing them elsewhere. Via webscraping, you can select data from web pages and store that data into a csv, database, etc.</p>

<p>There is a bit of legal ambiguity around the scraping of websites to be aware of. It seems to me that so long as the data you are scraping is meant for anybody who visits the site, it is likely ok. If you use it after you get past a paywall, that’s probably not legal. Here are a list of articles regarding the legality of it for those who are interested.</p>

<p><a href="https://thenextweb.com/security/2019/09/10/us-court-says-scraping-a-site-without-permission-isnt-illegal/">US court says scraping a site without permission isn’t illegal</a></p>

<p><a href="https://www.import.io/post/6-misunderstandings-about-web-scraping/">Is Web Scraping Legal? 6 Misunderstandings About Web Scraping</a></p>

<p><a href="http://scrapingauthority.com/2016/08/22/web-scraping-legal">Is Web Scraping Legal? Top 3 Legal Issues in Web Scraping</a></p>

<p><a href="https://towardsdatascience.com/is-web-crawling-legal-a758c8fcacde">Is web crawling legal?
</a></p>

<p>We’re going to be scraping data from wikipedia, which allows for web scraping. The site we will be scraping in particular is <a href="https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population">List of countries and dependencies by population</a>.</p>

<p><br /></p>

<h3 id="the-packages">The Packages</h3>

<p>We will be using urllib and BeautifulSoup to do out scraping. urllib is part of the Python standard library and should come with Python. If you do not already have BeautifulSoup, you can pip install it via</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">pip</span> <span class="n">install</span> <span class="n">beautifulsoup4</span>

</code></pre></div></div>

<p>pandas is also imported to help with the storing of the data later.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlopen</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>  
</code></pre></div></div>

<p>Once these are imported, we can access the web page using the urllib library. The following lines of code do the following:</p>

<p>1) Store the url in string format into a variable URL</p>

<p>2) Opens the web page at the given url</p>

<p>3) Reads in all the html data and stores this data into a variable called html</p>

<p>4) Closes the connection to the website</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">URL</span> <span class="o">=</span> <span class="s">'https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population'</span> <span class="c1"># 1)  
</span>
<span class="n">uClient</span> <span class="o">=</span> <span class="n">urlopen</span><span class="p">(</span><span class="n">URL</span><span class="p">)</span> <span class="c1"># 2)  
</span>
<span class="n">html</span> <span class="o">=</span> <span class="n">uClient</span><span class="o">.</span><span class="n">read</span><span class="p">()</span> <span class="c1"># 3)  
</span>
<span class="n">uClient</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> <span class="c1"># 4)  
</span></code></pre></div></div>

<p>If we observe the html variable from above, we see a mess of html data that was taken from the webpage. Below is a preview of the first of many many more lines.</p>

<p><img src="../../../assets/imgs/blogs/2020-02-09/html_mess.png" alt="" /></p>

<p>We can begin to clean this up with BS4. First we create a BeautifulSoup object, which allows us to use BeautifulSoup’s functions to parse through the html data. To make the object we pass our html variable created above and the type of parser we would like to use. We will be using ‘html.parser’ although there are more options than that. You can read about them <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser">here</a>. Once the soup object is created, your can use the prettify() method to observe a more structured output of the html data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span> <span class="c1"># Create soup object  
</span><span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">prettify</span><span class="p">())</span>  
</code></pre></div></div>

<p><img src="../../../assets/imgs/blogs/2020-02-09/prettify_html.png" alt="" /></p>

<h3 id="navigating-the-html-data">Navigating the HTML Data</h3>

<p>BeautifulSoup has methods that make finding data in the html easier. The way this works is by referencing the tags in the html (tags are what’s enclosed in the angel brackets; for example &lt; a &gt; is an anchor tag). You can search through the html by using the find_all method and passing the tag name you are interested in in brackets. One way to identify the tags of interest in a web page is by going to the web page, right clicking, and selecting “Inspect” as shown below (Google Chrome is being used here; may be different on other web browsers).<br />
<br />
<img src="../../../assets/imgs/blogs/2020-02-09/inspects.png" alt="" />
<br />
The html data will appear in the upper right corner as shown above. As you hover over the html, the corresonding parts on the web page will be highlighted. You can use this feature to see where the data you are interested in is located. For example, below we want to start at the table. Moving along through the html data shows us where we should start to gather this data.<br />
<br />
<img src="../../../assets/imgs/blogs/2020-02-09/highlight.png" alt="" />
<br /></p>
:ET